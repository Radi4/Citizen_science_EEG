{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Conv2D, Flatten, MaxPooling2D, UpSampling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from mne.io import read_raw_brainvision as mne_read\n",
    "from os.path import join\n",
    "from os import listdir\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channels_num = 60\n",
    "window_size = 500\n",
    "nb_epoch = 50\n",
    "\n",
    "# Hyper parameters\n",
    "batch_size = 32\n",
    "nb_visible = channels_num * window_size\n",
    "nb_hidden = 1000\n",
    "nb_emb = 20\n",
    "\n",
    "corruption_level = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mne_format_data_dir = join('data', 'resting_state_mne_format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inp = Input(shape=(window_size, channels_num, 1))\n",
    "\n",
    "    encoder = Sequential( [\n",
    "        Conv2D(256, kernel_size=(3,3), activation='relu', padding='same', input_shape=(window_size,channels_num,1)),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "        #MaxPooling2D(),\n",
    "        Conv2D(1, kernel_size=(1,1), padding='same'),\n",
    "    ] )\n",
    "    print(encoder.summary())\n",
    "    decoder = Sequential((\n",
    "        Conv2D(256, kernel_size=(3,3), activation='relu', padding='same', input_shape=(125, 15, 1) ),\n",
    "        UpSampling2D(),\n",
    "        Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "        #UpSampling2D(),\n",
    "        Conv2D(1, kernel_size=(1,1), padding='same'),\n",
    "    ))\n",
    "    print(decoder.summary())\n",
    "    autoencoder = Model(inp, decoder(encoder(inp)))\n",
    "    autoencoder.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "    print(autoencoder.summary())\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 500, 60, 256)      2560      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 250, 30, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 250, 30, 128)      295040    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 250, 30, 1)        129       \n",
      "=================================================================\n",
      "Total params: 297,729\n",
      "Trainable params: 297,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 125, 15, 256)      2560      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 250, 30, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 250, 30, 128)      295040    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 250, 30, 1)        129       \n",
      "=================================================================\n",
      "Total params: 297,729\n",
      "Trainable params: 297,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 500, 60, 1)        0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 250, 30, 1)        297729    \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    multiple                  297729    \n",
      "=================================================================\n",
      "Total params: 595,458\n",
      "Trainable params: 595,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "autoencoder = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "mean, var = None, None\n",
    "\n",
    "def cut_window(data):\n",
    "    return data[:, :data.shape[1] - data.shape[1] % window_size]\n",
    "\n",
    "def read_func(filename, verbose=0):\n",
    "    d = mne_read(filename, verbose=verbose, preload=True)\n",
    "    d.drop_channels(['VEOG', 'HEOG', 'STI 014'])\n",
    "    d = d.get_data()\n",
    "    return cut_window(np.vstack( [d, np.zeros( (2, d.shape[1]) )]) )\n",
    "\n",
    "def read_data(data_type, return_batch_np=False):\n",
    "    global mean, var\n",
    "    ''' If return_batch_np is False\n",
    "            return data with shape (None, batch_size, nb_visible)\n",
    "        else number of batches in data\n",
    "    '''\n",
    "    verbose = None if return_batch_np else 0\n",
    "    \n",
    "    data_dir = join(mne_format_data_dir, data_type)\n",
    "    data = np.hstack([read_func( join(data_dir, fn), verbose=verbose) for fn in listdir(data_dir) if fn[-5:] == '.vhdr'])\n",
    "    \n",
    "    if mean is None:\n",
    "        mean, var = data.mean(), data.var()\n",
    "    #data = scaler.transform(data)\n",
    "    data = (data - mean) / (var ** (1/2))\n",
    "    print(data_type, data.mean(), data.var())\n",
    "    if return_batch_np:\n",
    "        return data.shape[1] // window_size // batch_size\n",
    "    return data.T.reshape(-1, window_size, channels_num, 1)\n",
    "\n",
    "def gen(data_type):\n",
    "    data = read_data(data_type)\n",
    "    print(data.shape)\n",
    "    for ep in range(nb_epoch+1):\n",
    "        for i in range(data.shape[0] // batch_size):\n",
    "            x = data[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "            yield x, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from data/resting_state_mne_format/train/2505_shirokova_post_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 606599  =      0.000 ...   606.599 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/train/miloslavov_22_05_pre_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 603399  =      0.000 ...   603.399 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/train/gorin_rest_eeg_post_31011200.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 603699  =      0.000 ...   603.699 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/train/2704_zagirova_post_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 604549  =      0.000 ...   604.549 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/train/2103_glebko_posteeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 633899  =      0.000 ...   633.899 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/train/200317_ivanova_pre_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 602099  =      0.000 ...   602.099 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/train/gorbacheva_03_02_2017_post_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 603949  =      0.000 ...   603.949 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/train/2403_kutuzova_pre_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 602849  =      0.000 ...   602.849 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/train/08021400_post_eeg_shuhova.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 607199  =      0.000 ...   607.199 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/train/2103_kozunova_post_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 603199  =      0.000 ...   603.199 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/train/shuhova_08022017_rest_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 637949  =      0.000 ...   637.949 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/train/gorbacheva_03021300_rest_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 625249  =      0.000 ...   625.249 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/train/pre_egg_petuhova3103.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 602749  =      0.000 ...   602.749 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/train/zavrin_open_eyes_eeg_15021500.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 301999  =      0.000 ...   301.999 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/train/2003_ivanova_post_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 616599  =      0.000 ...   616.599 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/train/2403_kutuzova_posteeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 604199  =      0.000 ...   604.199 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/train/gorin_310117_rest_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 609999  =      0.000 ...   609.999 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/train/post_eeg_tsoy_2504.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 604949  =      0.000 ...   604.949 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/train/dagaev_post_rest_eeg_30011600.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 603799  =      0.000 ...   603.799 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/train/glebko_2103_pre_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 643749  =      0.000 ...   643.749 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/train/2505_shirokova.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 604799  =      0.000 ...   604.799 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/train/kozunova_pre_eeg_2103.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 602849  =      0.000 ...   602.849 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/train/bagaeva_post_eeg_13031500.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 603899  =      0.000 ...   603.899 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/train/bagaeva_13021500_rest_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 603949  =      0.000 ...   603.949 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/train/zagirova_pre_eeg_2704.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 607549  =      0.000 ...   607.549 secs...\n",
      "train -6.34378883316e-16 1.0\n",
      "Extracting parameters from data/resting_state_mne_format/validation/3103_petuhova_posteeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 630049  =      0.000 ...   630.049 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/validation/zavrib_post_eeg_eyesopen15021500.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 321599  =      0.000 ...   321.599 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/validation/2205_miloslavov_post_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 623249  =      0.000 ...   623.249 secs...\n",
      "validation -0.164368573828 0.135983946103\n"
     ]
    }
   ],
   "source": [
    "train_batches_nb = read_data('train', return_batch_np=True)\n",
    "val_batches_nb = read_data('validation', return_batch_np=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "autoencoder = load_model('models/cnn_x2_00.hdf5') # обучение прерывалось, в итоге проведено 3 эпохи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "train -6.34378883316e-16 1.0\n",
      "(29879, 500, 60, 1)\n",
      "932/933 [============================>.] - ETA: 8s - loss: 0.0353 - mean_absolute_error: 0.1369 validation -0.164368573828 0.135983946103\n",
      "(3149, 500, 60, 1)\n",
      "933/933 [==============================] - 8357s - loss: 0.0353 - mean_absolute_error: 0.1369 - val_loss: 0.0507 - val_mean_absolute_error: 0.1790\n",
      "Epoch 2/50\n",
      "933/933 [==============================] - 8316s - loss: 0.0418 - mean_absolute_error: 0.1391 - val_loss: 0.0594 - val_mean_absolute_error: 0.1889\n",
      "Epoch 3/50\n",
      "275/933 [=======>......................] - ETA: 5701s - loss: 0.0309 - mean_absolute_error: 0.1334"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ee4d0a512807>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = autoencoder.fit_generator(gen('train'), steps_per_epoch=train_batches_nb, epochs=nb_epoch,                           validation_data=gen('validation'), validation_steps=val_batches_nb,                           #use_multiprocessing=True, \\\n\u001b[0;32m----> 2\u001b[0;31m                           callbacks=[ModelCheckpoint(\"models/cnn_%s_{epoch:02d}.hdf5\" % ('x2'), save_best_only=False)])\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[1;32m   1838\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1839\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1563\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit_generator(gen('train'), steps_per_epoch=train_batches_nb, epochs=nb_epoch, \\\n",
    "                          validation_data=gen('validation'), validation_steps=val_batches_nb, \\\n",
    "                          #use_multiprocessing=True, \\\n",
    "                          callbacks=[ModelCheckpoint(\"models/cnn_%s_{epoch:02d}.hdf5\" % ('x2'), save_best_only=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from data/resting_state_mne_format/test/zavrin_eyes_closed_eeg_15021500.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 302749  =      0.000 ...   302.749 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/test/zavrin_15021500_eyesclosed_post_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 319299  =      0.000 ...   319.299 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/test/300120171600_dagaev_rest_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 615599  =      0.000 ...   615.599 secs...\n",
      "Extracting parameters from data/resting_state_mne_format/test/tsoy_pre_eeg_2504.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 652699  =      0.000 ...   652.699 secs...\n",
      "test -0.102788369207 0.114159913247\n"
     ]
    }
   ],
   "source": [
    "test_batches_nb = read_data('test', return_batch_np=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "autoencoder = load_model('models/cnn_x2_01.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred):\n",
    "    l2ratio = np.sum((y_true - y_pred)**2) / np.sum(y_true**2)\n",
    "    return np.sqrt(l2ratio) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test -0.102788369207 0.114159913247\n",
      "(3779, 500, 60, 1)\n",
      "44.1733951114\n",
      "54.7072529972\n",
      "63.6165421966\n",
      "61.725480184\n",
      "59.5827152153\n",
      "57.4937336196\n",
      "59.8050138551\n",
      "61.8361885811\n",
      "60.952260958\n",
      "59.5843298893\n",
      "58.8064642985\n",
      "60.6772702879\n",
      "61.229790427\n",
      "60.7395522172\n",
      "59.6786332029\n",
      "59.7376498832\n",
      "61.006266672\n",
      "60.9694207975\n",
      "60.5546350934\n",
      "59.7966718883\n",
      "60.2238764893\n",
      "61.1589938855\n",
      "60.8270312745\n",
      "60.3523191617\n",
      "59.8702304584\n",
      "60.5505744035\n",
      "60.9866933048\n",
      "60.7410139377\n",
      "60.2200398377\n",
      "60.0726178894\n",
      "60.7535601738\n",
      "60.8755723587\n",
      "60.6845202583\n",
      "60.2037934972\n",
      "60.3148207207\n",
      "60.9012588937\n",
      "60.7983268406\n",
      "60.5545173129\n",
      "60.1975504269\n",
      "60.5031575545\n",
      "60.9118138075\n",
      "60.7423870775\n",
      "60.4418370054\n",
      "60.1936641596\n",
      "60.6602851411\n",
      "60.8401670087\n",
      "60.701130234\n",
      "60.3611244101\n",
      "60.3545488598\n",
      "60.7731659643\n",
      "60.7860158591\n",
      "60.6479607499\n",
      "60.3524616656\n",
      "60.4860242374\n",
      "60.8650042497\n",
      "60.7436775865\n",
      "60.55454072\n",
      "60.3361463372\n",
      "60.6063185052\n",
      "60.8219629535\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "i = 0\n",
    "for test in gen('test'):\n",
    "    i += 1\n",
    "    x.append(metric(autoencoder.predict(test[0]), test[1]))\n",
    "    if (i % 25) == 0:\n",
    "        print(np.mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
